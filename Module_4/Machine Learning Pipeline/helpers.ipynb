{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ff65cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## utils isimlendirmesi de yapılabilir.\n",
    "## pipeline'da lazım olacak fonksiyonlar burada tutulur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cdb9c0ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Preprocessing & Feature Engineering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "05c42f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier, AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_validate, GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f57b4e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grab_col_names(df, cat_th=10, car_th=20):\n",
    "    \"\"\"\n",
    "\n",
    "    Veri setindeki kategorik, numerik ve kategorik fakat kardinal değişkenlerin isimlerini verir.\n",
    "    Not: Kategorik değişkenlerin içerisine numerik görünümlü kategorik değişkenler de dahildir.\n",
    "\n",
    "    Parameters\n",
    "    ------\n",
    "        df: df\n",
    "                Değişken isimleri alınmak istenilen df\n",
    "        cat_th: int, optional\n",
    "                numerik fakat kategorik olan değişkenler için sınıf eşik değeri\n",
    "        car_th: int, optinal\n",
    "                kategorik fakat kardinal değişkenler için sınıf eşik değeri\n",
    "\n",
    "    Returns\n",
    "    ------\n",
    "        cat_cols: list\n",
    "                Kategorik değişken listesi\n",
    "        num_cols: list\n",
    "                Numerik değişken listesi\n",
    "        cat_but_car: list\n",
    "                Kategorik görünümlü kardinal değişken listesi\n",
    "\n",
    "    Examples\n",
    "    ------\n",
    "        import seaborn as sns\n",
    "        df = sns.load_dataset(\"iris\")\n",
    "        print(grab_col_names(df))\n",
    "\n",
    "\n",
    "    Notes\n",
    "    ------\n",
    "        cat_cols + num_cols + cat_but_car = toplam değişken sayısı\n",
    "        num_but_cat cat_cols'un içerisinde.\n",
    "        Return olan 3 liste toplamı toplam değişken sayısına eşittir: cat_cols + num_cols + cat_but_car = değişken sayısı\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    # cat_cols, cat_but_car\n",
    "    cat_cols = [col for col in df.columns if df[col].dtypes == \"O\"]\n",
    "    num_but_cat = [col for col in df.columns if df[col].nunique() < cat_th and\n",
    "                   df[col].dtypes != \"O\"]\n",
    "    cat_but_car = [col for col in df.columns if df[col].nunique() > car_th and\n",
    "                   df[col].dtypes == \"O\"]\n",
    "    cat_cols = cat_cols + num_but_cat\n",
    "    cat_cols = [col for col in cat_cols if col not in cat_but_car]\n",
    "\n",
    "    # num_cols\n",
    "    num_cols = [col for col in df.columns if df[col].dtypes != \"O\"]\n",
    "    num_cols = [col for col in num_cols if col not in num_but_cat]\n",
    "\n",
    "    print(f\"Observations: {df.shape[0]}\")\n",
    "    print(f\"Variables: {df.shape[1]}\")\n",
    "    print(f'cat_cols: {len(cat_cols)}')\n",
    "    print(f'num_cols: {len(num_cols)}')\n",
    "    print(f'cat_but_car: {len(cat_but_car)}')\n",
    "    print(f'num_but_cat: {len(num_but_cat)}')\n",
    "    return cat_cols, num_cols, cat_but_car\n",
    "\n",
    "## verilen veri setindeki kategorik, sayısal, sayısal gibi görünen kategorik \n",
    "# ve kategorik gibi görünen ama kardinal olan değişkenleri döndürür."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce1587e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def outlier_thresholds(dataframe, col_name, q1=0.25, q3=0.75):\n",
    "    quartile1 = dataframe[col_name].quantile(q1)\n",
    "    quartile3 = dataframe[col_name].quantile(q3)\n",
    "    interquantile_range = quartile3 - quartile1\n",
    "    up_limit = quartile3 + 1.5 * interquantile_range\n",
    "    low_limit = quartile1 - 1.5 * interquantile_range\n",
    "    return low_limit, up_limit\n",
    "\n",
    "## kendisine girilen değişkenin alt ve üst eşik değerlerini \n",
    "# tanımlanmış yöntem ile hesaplamaktır\n",
    "# boxplot ile yapmaktadır"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "da69c462",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_with_thresholds(dataframe, variable, q1=0.25, q3=0.75):\n",
    "    low_limit, up_limit = outlier_thresholds(dataframe, variable, q1, q3)\n",
    "    dataframe.loc[(dataframe[variable] < low_limit), variable] = low_limit\n",
    "    dataframe.loc[(dataframe[variable] > up_limit), variable] = up_limit\n",
    "\n",
    "## aykırı değer varsa onun yerine eşik değer değerini koyar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cc619457",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encoder(dataframe, categorical_cols, drop_first=False):\n",
    "    dataframe = pd.get_dummies(dataframe, columns=categorical_cols, drop_first=drop_first)\n",
    "    return dataframe\n",
    "\n",
    "## -türeteceğimiz yeni- kategorik değişkenleri biçimlendirir\n",
    "# drop_first True dersek one hot encoderi label encoder olarak da kullanmış oluruz\n",
    "# yani iki değişkenli kategorikleri de encoderdan geçirmiş olacak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a1c25320",
   "metadata": {},
   "outputs": [],
   "source": [
    "# yukarıda tek tek yaptıgımız veri on isleme adımlarının fonksiyonlasması\n",
    "def diabetes_data_prep(dataframe):\n",
    "    dataframe.columns = [col.upper() for col in dataframe.columns]\n",
    "\n",
    "    # Glucose\n",
    "    dataframe['NEW_GLUCOSE_CAT'] = pd.cut(x=dataframe['GLUCOSE'], bins=[-1, 139, 200], labels=[\"normal\", \"prediabetes\"])\n",
    "\n",
    "    # Age\n",
    "    dataframe.loc[(dataframe['AGE'] < 35), \"NEW_AGE_CAT\"] = 'young'\n",
    "    dataframe.loc[(dataframe['AGE'] >= 35) & (dataframe['AGE'] <= 55), \"NEW_AGE_CAT\"] = 'middleage'\n",
    "    dataframe.loc[(dataframe['AGE'] > 55), \"NEW_AGE_CAT\"] = 'old'\n",
    "\n",
    "    # BMI\n",
    "    dataframe['NEW_BMI_RANGE'] = pd.cut(x=dataframe['BMI'], bins=[-1, 18.5, 24.9, 29.9, 100],\n",
    "                                        labels=[\"underweight\", \"healty\", \"overweight\", \"obese\"])\n",
    "\n",
    "    # BloodPressure\n",
    "    dataframe['NEW_BLOODPRESSURE'] = pd.cut(x=dataframe['BLOODPRESSURE'], bins=[-1, 79, 89, 123],\n",
    "                                            labels=[\"normal\", \"hs1\", \"hs2\"])\n",
    "\n",
    "    cat_cols, num_cols, cat_but_car = grab_col_names(dataframe, cat_th=5, car_th=20)\n",
    "\n",
    "    cat_cols = [col for col in cat_cols if \"OUTCOME\" not in col]\n",
    "\n",
    "    df = one_hot_encoder(dataframe, cat_cols, drop_first=True)\n",
    "\n",
    "    df.columns = [col.upper() for col in df.columns]\n",
    "\n",
    "    cat_cols, num_cols, cat_but_car = grab_col_names(df, cat_th=5, car_th=20)\n",
    "\n",
    "    cat_cols = [col for col in cat_cols if \"OUTCOME\" not in col]\n",
    "\n",
    "    replace_with_thresholds(df, \"INSULIN\")\n",
    "\n",
    "    X_scaled = StandardScaler().fit_transform(df[num_cols])\n",
    "    df[num_cols] = pd.DataFrame(X_scaled, columns=df[num_cols].columns)\n",
    "\n",
    "    y = df[\"OUTCOME\"]\n",
    "    X = df.drop([\"OUTCOME\"], axis=1)\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0b722a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "86f94eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def base_models(X,y,scoring=\"roc_auc\"):\n",
    "    print(\"Base models....\")\n",
    "    classifiers = [(\"LR\",LogisticRegression()),\n",
    "                   (\"KNN\",KNeighborsClassifier()),\n",
    "                   (\"SVC\",SVC()),\n",
    "                   (\"CART\",DecisionTreeClassifier()),\n",
    "                   (\"RF\",RandomForestClassifier()),\n",
    "                   (\"Adaboost\",AdaBoostClassifier()),\n",
    "                   (\"GBM\",GradientBoostingClassifier()),\n",
    "                   (\"XGBoost\",XGBClassifier(use_label_encoder=False,eval_metric=\"logloss\")),\n",
    "                   (\"LightGBM\",LGBMClassifier(verbose=-1)),\n",
    "                   (\"CatBoost\",CatBoostClassifier(verbose=False))\n",
    "                  ]\n",
    "    for name, classifier in classifiers:\n",
    "        cv_results = cross_validate(classifier,X,y,cv=3,scoring=scoring)\n",
    "        print(f\"{scoring}: {round(cv_results['test_score'].mean(),4)} ({name})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bdcf1272",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "79e2904c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# birden fazla modelin birden fazla arama görevini bir fonksiyon ile otomatik şekilde gerçekleşmesi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "694263c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyperparameter_optimization(X,y,cv=3,scoring=\"roc_auc\"):\n",
    "    knn_params = {\"n_neighbors\": range(2, 50)}\n",
    "\n",
    "    cart_params = {'max_depth': range(1, 20),\n",
    "               \"min_samples_split\": range(2, 30)}\n",
    "\n",
    "    rf_params = {\"max_depth\": [8, 15, None],\n",
    "             \"max_features\": [5, 7, \"auto\"],\n",
    "             \"min_samples_split\": [15, 20],\n",
    "             \"n_estimators\": [200, 300]}\n",
    "\n",
    "    xgboost_params = {\"learning_rate\": [0.1, 0.01],\n",
    "                  \"max_depth\": [5, 8],\n",
    "                  \"n_estimators\": [100, 200]}\n",
    "\n",
    "    lightgbm_params = {\"learning_rate\": [0.01, 0.1],\n",
    "                   \"n_estismators\": [300, 500]}\n",
    "\n",
    "\n",
    "    classifiers = [('KNN', KNeighborsClassifier(), knn_params),\n",
    "               (\"CART\", DecisionTreeClassifier(), cart_params),\n",
    "               (\"RF\", RandomForestClassifier(), rf_params),\n",
    "               ('XGBoost', XGBClassifier(use_label_encoder=False, eval_metric='logloss'), xgboost_params),\n",
    "               ('LightGBM', LGBMClassifier(verbose=-1), lightgbm_params)]\n",
    "    \n",
    "    print(\"Hyperparameter optimization....\")\n",
    "    best_models = {} # görevi en iyi modelleri tutmak\n",
    "    for name, classifier, params in classifiers:\n",
    "        print(f\"########### {name} ###########\") # calısan modelin adı\n",
    "        cv_results = cross_validate(classifier,X,y,cv=cv,scoring=scoring) # optimize edilmemis skorun hesaplanması\n",
    "        print(f\"{scoring} (Before): {round(cv_results['test_score'].mean(),4)}\") # skorun yazdırılması\n",
    "        \n",
    "    # modelin parametre optimizasyonunun yapılması\n",
    "        gs_best = GridSearchCV(classifier,params,cv=cv,n_jobs=-1,verbose=False).fit(X,y)\n",
    "    # grid searchten gelen parametrelerle eski modeli set eder\n",
    "        final_model = classifier.set_params(**gs_best.best_params_)\n",
    "        \n",
    "        cv_results = cross_validate(final_model,X,y,cv=cv,scoring=scoring) # optimize edilmiş skorun hesaplanması\n",
    "        print(f\"{scoring} (After): {round(cv_results['test_score'].mean(),4)}\") # skorun yazdırılması\n",
    "        print(f\"{name} best params: {gs_best.best_params_}\", end=\"\\n\\n\") # en iyi parametrelerin yazdırılması\n",
    "        best_models[name] = final_model # sözlüğe aktarılır\n",
    "    return best_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8fbfba7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stacking & Ensemble Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "024c008a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def voting_classifier(best_models,X,y):\n",
    "    print(\"Voting classifier....\")\n",
    "    voting_clf = VotingClassifier(estimators=[(\"KNN\",best_models[\"KNN\"]),\n",
    "                                             (\"RF\",best_models[\"RF\"]),\n",
    "                                              (\"LightGBM\",best_models[\"LightGBM\"])],voting=\"soft\").fit(X,y)\n",
    "    cv_results = cross_validate(voting_clf,X,y,cv=3,scoring=[\"accuracy\",\"f1\",\"roc_auc\"])\n",
    "    print(f\"Accuracy: {cv_results['test_accuracy'].mean()}\")\n",
    "    print(f\"F1Score: {cv_results['test_f1'].mean()}\")\n",
    "    print(f\"ROC_AUC: {cv_results['test_roc_auc'].mean()}\")\n",
    "    return voting_clf\n",
    "## hard- en fazla tahmin edilen sınıfı döndürür\n",
    "## soft- sınıf gerçekleşme olasılıkları üzerinden oylama yapılır"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c365a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c5c411",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
